# LLaMa-Herd Docker Environment Configuration
# Copy this file to .env and modify values as needed

# =============================================================================
# DOCKER COMPOSE CONFIGURATION
# =============================================================================

# Docker Compose Project Name (optional)
# COMPOSE_PROJECT_NAME=llama-herd

# =============================================================================
# BACKEND CONFIGURATION
# =============================================================================

# API Configuration
API_HOST=0.0.0.0
API_PORT=8000
API_TITLE="LLaMa-Herd Backend"
API_VERSION="1.0.0"

# CORS Configuration
# Note: In Docker, frontend runs on different ports for dev/prod
CORS_ORIGINS="http://localhost:3000,http://localhost:80,http://localhost"
CORS_ALLOW_CREDENTIALS=true
CORS_ALLOW_METHODS="*"
CORS_ALLOW_HEADERS="*"

# Ollama Configuration
# In Docker, Ollama service is accessible via container name 'ollama'
OLLAMA_BASE_URL=http://ollama:11434/v1
OLLAMA_URL=http://ollama:11434
OLLAMA_API_KEY=ollama
OLLAMA_TIMEOUT=300
OLLAMA_MODELS_DIR=/root/.ollama/models

# Storage Configuration
DATA_DIRECTORY=/app/data
EXPERIMENTS_DIRECTORY=experiments
CONVERSATIONS_DIRECTORY=conversations

# Experiment Configuration
DEFAULT_MAX_ROUNDS=8
DEFAULT_TEMPERATURE=0.7
EXPERIMENT_TIMEOUT_SECONDS=3600
ITERATION_TIMEOUT_SECONDS=300

# Pull Configuration
PULL_PROGRESS_THROTTLE_MS=500
PULL_PROGRESS_PERCENT_DELTA=2.0

# =============================================================================
# FRONTEND CONFIGURATION
# =============================================================================

# React App Environment Variables
# These are used during build time for the frontend
REACT_APP_API_BASE_URL=http://localhost:8000
REACT_APP_OLLAMA_BASE_URL=http://localhost:11435

# =============================================================================
# DEVELOPMENT CONFIGURATION
# =============================================================================

# Development-specific settings
# Uncomment and modify for development environment

# Enable hot reload for frontend development
# CHOKIDAR_USEPOLLING=true
# WATCHPACK_POLLING=true

# Enable debug logging
# LOG_LEVEL=debug

# =============================================================================
# PRODUCTION CONFIGURATION
# =============================================================================

# Production-specific settings
# Uncomment and modify for production environment

# Disable debug features
# LOG_LEVEL=info

# Enable production optimizations
# NODE_ENV=production

# =============================================================================
# VOLUME CONFIGURATION
# =============================================================================

# Docker volume names (automatically managed by docker-compose)
# experiment-data: Stores experiments and conversations
# ollama-models: Stores downloaded AI models

# =============================================================================
# NETWORK CONFIGURATION
# =============================================================================

# Docker network name (automatically managed by docker-compose)
# llama-herd-network: Internal network for container communication

# =============================================================================
# USAGE INSTRUCTIONS
# =============================================================================

# 1. Copy this file to .env:
#    cp .env.example .env

# 2. Modify values as needed for your environment

# 3. Start development environment:
#    docker-compose --profile dev up

# 4. Start production environment:
#    docker-compose --profile prod up -d

# 5. Pull AI models:
#    docker-compose exec ollama ollama pull llama2
#    docker-compose exec ollama ollama pull codellama

# 6. Access the application:
#    Development: http://localhost:3000
#    Production: http://localhost:80
#    Backend API: http://localhost:8000
#    API Docs: http://localhost:8000/docs
#    Ollama API: http://localhost:11435

# =============================================================================
# TROUBLESHOOTING
# =============================================================================

# If you encounter issues:

# 1. Check container logs:
#    docker-compose logs [service-name]

# 2. Check container health:
#    docker-compose ps

# 3. Restart services:
#    docker-compose restart [service-name]

# 4. Rebuild containers:
#    docker-compose build --no-cache

# 5. Clean up volumes (WARNING: This will delete all data):
#    docker-compose down -v

